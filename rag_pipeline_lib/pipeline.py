"""
REAPæ¡†æ¶ä¸»æµç¨‹æ¨¡å—ï¼ˆpipeline.pyï¼‰

æœ¬æ¨¡å—å®ç°äº†REAPï¼ˆRecursive Evaluation and Adaptive Planningï¼‰æ¡†æ¶çš„å®Œæ•´æ‰§è¡Œæµç¨‹ï¼Œ
é€šè¿‡"åˆ†è§£-è¿­ä»£è§„åˆ’-äº‹å®æå–-åˆæˆ"çš„é—­ç¯æµç¨‹ï¼Œå®ç°å¤šè·³é—®ç­”ï¼ˆMHQAï¼‰çš„ç²¾å‡†æ¨ç†ã€‚

REAPæ¡†æ¶å®Œæ•´æµç¨‹ï¼š
1. é˜¶æ®µ1ï¼šåˆå§‹æŸ¥è¯¢åˆ†è§£ï¼ˆDecomposeræ¨¡å—ï¼‰
   - å°†å¤æ‚æŸ¥è¯¢Qæ‹†è§£ä¸ºç»“æ„åŒ–åˆå§‹ä»»åŠ¡è®¡åˆ’Pâ‚€
2. é˜¶æ®µ2ï¼šæ ¸å¿ƒè¿­ä»£å¾ªç¯ï¼ˆSPä¸FEååŒï¼‰
   - å­æ­¥éª¤2.1ï¼šSPåˆ†æçŠ¶æ€ï¼Œç¡®å®šå¯æ‰§è¡ŒåŠ¨ä½œActionsâ‚œ
   - å­æ­¥éª¤2.2ï¼šFEå¤„ç†Actionsâ‚œï¼Œæå–ç»“æ„åŒ–äº‹å®fâ‚œ
   - å­æ­¥éª¤2.3ï¼šSPæ›´æ–°è®¡åˆ’ä¸äº‹å®ï¼Œè¿›å…¥ä¸‹ä¸€è½®è¿­ä»£
   - è¿­ä»£ç»ˆæ­¢æ¡ä»¶ï¼šæ‰€æœ‰å­ä»»åŠ¡å®Œæˆã€è¿ç»­å¤±è´¥ã€è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
3. é˜¶æ®µ3ï¼šç­”æ¡ˆåˆæˆï¼ˆSynthesizeræ¨¡å—ï¼‰
   - åŸºäºæœ€ç»ˆäº‹å®åˆ—è¡¨F_finalåˆæˆæœ€ç»ˆç­”æ¡ˆA

è¿­ä»£ç»ˆæ­¢æ¡ä»¶ï¼ˆæ»¡è¶³ä»»ä¸€å³åœæ­¢ï¼‰ï¼š
1. æ‰€æœ‰å­ä»»åŠ¡å®Œæˆï¼Œäº‹å®åˆ—è¡¨Fâ‚œå·²è¦†ç›–åŸå§‹æŸ¥è¯¢æ‰€éœ€ä¿¡æ¯
2. è¿ç»­å¤šè½®ï¼ˆå¦‚2è½®ï¼‰æå–åˆ°PartialClue/Failedï¼Œä¸”Re-Planneræ— æ³•ç”Ÿæˆæœ‰æ•ˆæ–°å­ä»»åŠ¡
3. è¿­ä»£æ¬¡æ•°è¾¾åˆ°é¢„è®¾ä¸Šé™ï¼ˆé»˜è®¤5æ¬¡ï¼‰
"""
from concurrent.futures import ThreadPoolExecutor, as_completed
from rag_pipeline_lib import core as rag_core
from contextvars import ContextVar, copy_context
from functools import partial
import json
import copy

# è¿½è¸ªå™¨ä¸Šä¸‹æ–‡å˜é‡ï¼Œç”¨äºè®°å½•LLMè°ƒç”¨å’Œè¿­ä»£ä¿¡æ¯
tracer_context: ContextVar = ContextVar('tracer_context', default=None)

# æ•ˆç‡ç”»åƒï¼šä½¿ç”¨ rag_pipeline_lib.efficiency_stats çš„ contextï¼Œç”±è¯„æµ‹è„šæœ¬åœ¨æ¯æ ·æœ¬è®¾ç½®
from rag_pipeline_lib.efficiency_stats import efficiency_stats_context

class Tracer:
    """
    è¿½è¸ªå™¨ç±»ï¼šç”¨äºè®°å½•REAPæ¡†æ¶æ‰§è¡Œè¿‡ç¨‹ä¸­çš„LLMè°ƒç”¨å’Œè¿­ä»£ä¿¡æ¯
    
    åŠŸèƒ½ï¼š
    - è®°å½•æ¯æ¬¡LLMè°ƒç”¨çš„è¾“å…¥å’Œè¾“å‡º
    - è·Ÿè¸ªè¿­ä»£æ¬¡æ•°
    - æ”¯æŒæäº¤å’Œä¸¢å¼ƒå¾…å¤„ç†çš„æ—¥å¿—ï¼ˆç”¨äºé”™è¯¯å›æ»šï¼‰
    """
    def __init__(self):
        self.log = []  # å·²æäº¤çš„æ—¥å¿—åˆ—è¡¨
        self.iteration_count = 0  # å½“å‰è¿­ä»£æ¬¡æ•°
        self._pending_log = []  # å¾…å¤„ç†çš„æ—¥å¿—åˆ—è¡¨ï¼ˆç”¨äºé”™è¯¯å›æ»šï¼‰

    def record_llm_call(self, adapter_function_name, inputs, output, duration_s=None):
        """è®°å½•ä¸€æ¬¡LLMè°ƒç”¨ï¼Œå¯é€‰è®°å½•å•æ¬¡è€—æ—¶ duration_sï¼ˆç§’ï¼‰ã€‚"""
        trace_entry = {
            "adapter_function_name": adapter_function_name,
            "llm_inputs": copy.deepcopy(inputs),
            "llm_output": copy.deepcopy(output)
        }
        if duration_s is not None:
            trace_entry["duration_s"] = duration_s
        self._pending_log.append(trace_entry)

    def commit_pending(self):
        """æäº¤å¾…å¤„ç†çš„æ—¥å¿—åˆ°æ­£å¼æ—¥å¿—åˆ—è¡¨"""
        self.log.extend(self._pending_log)
        self._pending_log.clear()

    def discard_pending(self):
        """ä¸¢å¼ƒå¾…å¤„ç†çš„æ—¥å¿—ï¼ˆç”¨äºé”™è¯¯å›æ»šï¼‰"""
        self._pending_log.clear()

def run_multistep_pipeline(query: str, verbose: bool = True, trace_collector: Tracer = None, serial_next_actions: bool = False) -> str:
    """
    REAPæ¡†æ¶ä¸»æ‰§è¡Œå‡½æ•°ï¼šå®ç°å®Œæ•´çš„"åˆ†è§£-è¿­ä»£è§„åˆ’-äº‹å®æå–-åˆæˆ"æµç¨‹
    
    è¿™æ˜¯REAPæ¡†æ¶çš„å…¥å£å‡½æ•°ï¼Œåè°ƒDecomposerã€SPï¼ˆå­ä»»åŠ¡è§„åˆ’å™¨ï¼‰å’ŒFEï¼ˆäº‹å®æå–å™¨ï¼‰
    ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ï¼Œé€šè¿‡é€’å½’ååŒå®ç°å¤šè·³é—®ç­”çš„ç²¾å‡†æ¨ç†ã€‚
    
    æµç¨‹æ¦‚è¿°ï¼š
    1. é˜¶æ®µ1ï¼šåˆå§‹æŸ¥è¯¢åˆ†è§£ - è°ƒç”¨analyze_and_decompose_queryç”Ÿæˆåˆå§‹ä»»åŠ¡è®¡åˆ’Pâ‚€
    2. é˜¶æ®µ2ï¼šæ ¸å¿ƒè¿­ä»£å¾ªç¯ - SPä¸FEååŒï¼Œé€æ­¥å®Œå–„äº‹å®åˆ—è¡¨å’Œä»»åŠ¡è®¡åˆ’
    3. é˜¶æ®µ3ï¼šç­”æ¡ˆåˆæˆ - è°ƒç”¨synthesize_final_answerç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
    
    Args:
        query: ç”¨æˆ·çš„å¤æ‚å¤šè·³æŸ¥è¯¢Q
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†æ‰§è¡Œä¿¡æ¯
        trace_collector: å¯é€‰çš„è¿½è¸ªå™¨å¯¹è±¡ï¼Œç”¨äºè®°å½•æ‰§è¡Œè¿‡ç¨‹
        serial_next_actions: è‹¥ Trueï¼Œnext_actions ä¸²è¡Œæ‰§è¡Œï¼ˆç”¨äº Parallel vs Serial å¯¹æ¯”å®éªŒã€wall-clock/QPSï¼‰
        
    Returns:
        str: åŸå§‹æŸ¥è¯¢çš„æœ€ç»ˆç­”æ¡ˆA
    """
    current_tracer = tracer_context.get()

    if verbose:
        print(f"\nğŸš€ Starting new multi-step pipeline for query: '{query}'")

    # ========== é˜¶æ®µ1ï¼šåˆå§‹æŸ¥è¯¢åˆ†è§£ï¼ˆDecomposeræ¨¡å—ï¼‰==========
    # åŠŸèƒ½ï¼šå°†å¤æ‚æŸ¥è¯¢Qæ‹†è§£ä¸ºç»“æ„åŒ–åˆå§‹ä»»åŠ¡è®¡åˆ’Pâ‚€ = {pâ‚, pâ‚‚, ..., pâ‚™}
    # æ¯ä¸ªå­ä»»åŠ¡páµ¢çš„æ ¼å¼ä¸º(idáµ¢, qáµ¢, depsáµ¢)
    analysis_result = None
    max_analysis_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
    # é‡è¯•æœºåˆ¶ï¼šå¦‚æœæŸ¥è¯¢åˆ†è§£å¤±è´¥ï¼Œæœ€å¤šé‡è¯•3æ¬¡
    for attempt in range(max_analysis_retries):
        try:
            if verbose and attempt > 0:
                print(f"ğŸ”„ Retrying query analysis... (Attempt {attempt + 1}/{max_analysis_retries})")
            
            # ä¸¢å¼ƒä¹‹å‰å¤±è´¥çš„æ—¥å¿—ï¼ˆå¦‚æœæœ‰ï¼‰
            if current_tracer: current_tracer.discard_pending()
            # è°ƒç”¨Decomposeræ¨¡å—è¿›è¡ŒæŸ¥è¯¢åˆ†è§£
            analysis_result = rag_core.analyze_and_decompose_query(query=query)
            
            # éªŒè¯åˆ†è§£ç»“æœçš„æœ‰æ•ˆæ€§
            if not analysis_result or "requirements" not in analysis_result:
                raise ValueError("Analysis result is empty or missing 'requirements' key.")
            
            # æäº¤æˆåŠŸçš„æ—¥å¿—
            if current_tracer: current_tracer.commit_pending()
            if verbose: print("âœ… Query analysis successful.")
            break 
        except Exception as e:
            if verbose:
                print(f"âŒ Query analysis failed on attempt {attempt + 1}. Error: {e}")
            # å¦‚æœè¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè¿”å›é”™è¯¯
            if attempt == max_analysis_retries - 1:
                if current_tracer: current_tracer.discard_pending()
                error_msg = f"Pipeline Error: Failed to analyze and decompose the query after {max_analysis_retries} attempts."
                if verbose: print(f"\nâŒ {error_msg}")
                return error_msg
    
    if not analysis_result:
        return "Pipeline Error: Could not obtain a valid query analysis."

    if verbose:
        print("--- Initial Analysis and Requirements ---")
        print(json.dumps(analysis_result, indent=2, ensure_ascii=False))
        print("------------------------------------")

    # ========== åˆå§‹åŒ–çŠ¶æ€å˜é‡ ==========
    # è¿™äº›å˜é‡å°†åœ¨è¿­ä»£å¾ªç¯ä¸­ä¸æ–­æ›´æ–°
    all_requirements = analysis_result.get("requirements", [])  # æ‰€æœ‰å­ä»»åŠ¡åˆ—è¡¨ï¼ˆåˆå§‹ä»»åŠ¡è®¡åˆ’Pâ‚€ï¼‰
    pending_requirements = list(all_requirements)  # å¾…å®Œæˆçš„å­ä»»åŠ¡åˆ—è¡¨ï¼ˆå½“å‰ä»»åŠ¡è®¡åˆ’P_tï¼‰
    req_id_to_question = {req['requirement_id']: req['question'] for req in all_requirements}  # å­ä»»åŠ¡IDåˆ°é—®é¢˜çš„æ˜ å°„
    collected_facts = {"reasoned_facts": []}  # æ”¶é›†çš„äº‹å®åˆ—è¡¨F_tï¼ˆåˆå§‹ä¸ºç©ºFâ‚€=âˆ…ï¼‰
    max_iterations = 5  # æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆè®ºæ–‡ä¸­è®¾ä¸º5ï¼‰
    max_total_attempts = 10  # æœ€å¤§æ€»å°è¯•æ¬¡æ•°ï¼ˆåŒ…æ‹¬å¤±è´¥é‡è¯•ï¼‰
    last_extraction_was_direct_only = True  # æ ‡è®°ä¸Šä¸€è½®æå–æ˜¯å¦å…¨éƒ¨ä¸ºDirectAnswerï¼ˆç”¨äºé€‰æ‹©Plan Updateræˆ–Re-Plannerï¼‰ 

    # ========== é˜¶æ®µ2ï¼šæ ¸å¿ƒè¿­ä»£å¾ªç¯ï¼ˆSPä¸FEååŒï¼‰==========
    # è¿™æ˜¯REAPæ¡†æ¶çš„æ ¸å¿ƒç¯èŠ‚ï¼Œé€šè¿‡SPï¼ˆæˆ˜ç•¥è§„åˆ’ï¼‰ä¸FEï¼ˆäº‹å®é‡‡é›†ï¼‰çš„é€’å½’äº¤äº’ï¼Œ
    # é€æ­¥å®Œå–„äº‹å®åˆ—è¡¨ã€ä¼˜åŒ–ä»»åŠ¡è®¡åˆ’ï¼Œç›´åˆ°æ»¡è¶³ç»ˆæ­¢æ¡ä»¶
    iteration_count = 0  # å½“å‰è¿­ä»£æ¬¡æ•°ï¼ˆæˆåŠŸå®Œæˆçš„è¿­ä»£æ•°ï¼‰
    total_attempt_count = 0  # æ€»å°è¯•æ¬¡æ•°ï¼ˆåŒ…æ‹¬å¤±è´¥é‡è¯•ï¼‰
    while iteration_count < max_iterations:
        total_attempt_count += 1  # æ¯æ¬¡å¾ªç¯å¢åŠ æ€»å°è¯•æ¬¡æ•°
        # ç»ˆæ­¢æ¡ä»¶1ï¼šè¾¾åˆ°æœ€å¤§æ€»å°è¯•æ¬¡æ•°ï¼ˆé˜²æ­¢æ— é™é‡è¯•ï¼‰
        if total_attempt_count > max_total_attempts:
            if verbose: print(f"\nâš ï¸ Warning: Reached maximum total attempts ({max_total_attempts}) due to repeated failures. Moving to synthesis.")
            break

        # ç»ˆæ­¢æ¡ä»¶2ï¼šæ‰€æœ‰å­ä»»åŠ¡å·²å®Œæˆï¼ˆç†æƒ³ç»ˆæ­¢æ¡ä»¶ï¼‰
        if not pending_requirements:
            if verbose: print("\nâœ… All requirements have been fulfilled. Moving to final answer synthesis.")
            break
        
        # æ›´æ–°è¿½è¸ªå™¨çš„è¿­ä»£è®¡æ•°
        if current_tracer:
            current_tracer.iteration_count = iteration_count + 1
            # åœ¨æ¯æ¬¡è¿­ä»£å¼€å§‹æ—¶ï¼Œä¸¢å¼ƒä¹‹å‰å¤±è´¥çš„æ—¥å¿—ï¼ˆç”¨äºé”™è¯¯å›æ»šï¼‰
            current_tracer.discard_pending()

        if verbose:
            print(f"\n--- Iteration {iteration_count + 1}/{max_iterations} ---")
            print(f"ğŸ“ Pending Requirements: {[req['question'] for req in pending_requirements]}")

        # ========== çŠ¶æ€å¿«ç…§ï¼šä¿å­˜è¿­ä»£å¼€å§‹å‰çš„çŠ¶æ€ï¼ˆç”¨äºé”™è¯¯å›æ»šï¼‰==========
        # å¦‚æœè¿­ä»£è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œå¯ä»¥å›æ»šåˆ°è¿™äº›çŠ¶æ€
        facts_before_iteration = [fact for fact in collected_facts["reasoned_facts"]]  # è¿­ä»£å‰çš„äº‹å®åˆ—è¡¨F_{t-1}
        pending_reqs_before_iteration = list(pending_requirements)  # è¿­ä»£å‰çš„å¾…å®Œæˆè®¡åˆ’P_{t-1}
        req_map_before_iteration = dict(req_id_to_question)  # è¿­ä»£å‰çš„IDæ˜ å°„
        last_direct_before_iteration = last_extraction_was_direct_only  # è¿­ä»£å‰çš„æå–çŠ¶æ€æ ‡è®°
        
        try:
            # ========== å­æ­¥éª¤2.1ï¼šSPåˆ†æçŠ¶æ€ï¼Œç¡®å®šå¯æ‰§è¡ŒåŠ¨ä½œActionsâ‚œ ==========
            # SPä»å…¨å±€è§†è§’è¯„ä¼°å½“å‰æ¨ç†çŠ¶æ€ï¼Œåˆ¤æ–­å“ªäº›å­ä»»åŠ¡å·²æ»¡è¶³ä¾èµ–æ¡ä»¶ï¼ˆå³å‰ç½®å­ä»»åŠ¡çš„äº‹å®å·²æå–ï¼‰ï¼Œ
            # å°†å…¶ç¡®å®šä¸º"å¯æ‰§è¡ŒåŠ¨ä½œ"ï¼ˆActionsâ‚œï¼‰
            # 
            # æ ¹æ®ä¸Šä¸€è½®æå–ç»“æœçš„æ»¡è¶³åº¦æ ‡ç­¾lâ‚œï¼Œé€‰æ‹©ä¸åŒçš„è§„åˆ’ç­–ç•¥ï¼š
            # - è‹¥lâ‚œ=DirectAnswerï¼ˆç†æƒ³åœºæ™¯ï¼‰â†’ è°ƒç”¨Plan Updaterï¼ˆè½»é‡çº§ï¼Œæ‰§è¡Œäº‹å®æ›¿æ¢å’Œè®¡åˆ’åˆ†å‰ï¼‰
            # - è‹¥lâ‚œ=PartialClue/Failedï¼ˆéç†æƒ³åœºæ™¯ï¼‰â†’ è°ƒç”¨Re-Plannerï¼ˆå®Œæ•´è§„åˆ’ï¼Œæ‰§è¡Œå®ç”¨å……åˆ†æ€§è¯„ä¼°å’ŒèŒƒå›´åŒ–è®¡åˆ’ä¿®å¤ï¼‰
            decision_result = None
            if last_extraction_was_direct_only:
                # ä¸Šä¸€è½®æå–å…¨éƒ¨ä¸ºDirectAnswerï¼Œä½¿ç”¨è½»é‡çº§Plan Updater
                if verbose: print("\nğŸ”„ Last extraction was successful. Using lightweight 'update_plan'.")
                decision_result = rag_core.update_plan(query=query, collected_facts=collected_facts, pending_requirements=pending_requirements)
            else:
                # ä¸Šä¸€è½®æå–åŒ…å«PartialClueæˆ–Failedï¼Œä½¿ç”¨å®Œæ•´Re-Planner
                if verbose: print("\nğŸ¤” Last extraction had partial clues or failures. Using full 'replan_questions'.")
                decision_result = rag_core.replan_questions(query=query, collected_facts=collected_facts, pending_requirements=pending_requirements)

            # éªŒè¯è§„åˆ’ç»“æœçš„æœ‰æ•ˆæ€§
            if not decision_result or "decision" not in decision_result:
                raise ValueError("Planning step failed to return a valid decision.")
            if verbose:
                print("--- Planning Decision ---")
                print(json.dumps(decision_result, indent=2, ensure_ascii=False))
                print("-------------------------")
            decision = decision_result.get("decision", {})

            # ========== å­æ­¥éª¤2.3ï¼ˆéƒ¨åˆ†ï¼‰ï¼šSPæ›´æ–°ä»»åŠ¡è®¡åˆ’P_t ==========
            # æ ¹æ®SPè¿”å›çš„updated_planï¼Œæ›´æ–°å¾…å®Œæˆçš„å­ä»»åŠ¡åˆ—è¡¨
            # è¿™å¯¹åº”è®ºæ–‡ä¸­çš„è®¡åˆ’æ›´æ–°ï¼šP_t = SP(P_{t-1}, F_t, Q)
            if "updated_plan" in decision and isinstance(decision["updated_plan"], list):
                if verbose: print("ğŸ”„ Updating pending requirements based on the new plan.")
                pending_requirements = decision["updated_plan"]  # æ›´æ–°ä¸ºæ–°çš„ä»»åŠ¡è®¡åˆ’P_t
                req_id_to_question = {req['requirement_id']: req['question'] for req in pending_requirements}  # æ›´æ–°IDæ˜ å°„

            # æ£€æŸ¥SPçš„å†³ç­–ï¼šæ˜¯å¦ç»§ç»­æœç´¢æˆ–ç›´æ¥åˆæˆç­”æ¡ˆ
            next_step = decision.get("next_step")
            if next_step == "SYNTHESIZE_ANSWER":
                # SPåˆ¤æ–­æ‰€æœ‰å¿…è¦äº‹å®å·²æ”¶é›†ï¼Œå¯ä»¥è¿›å…¥ç­”æ¡ˆåˆæˆé˜¶æ®µ
                if verbose: print("âœ… Planning module decided all necessary facts are collected. Moving to synthesis.")
                if current_tracer: current_tracer.commit_pending()
                break
            
            # éªŒè¯next_stepçš„æœ‰æ•ˆæ€§
            if next_step != "CONTINUE_SEARCH":
                raise ValueError(f"Received unexpected next step '{next_step}'.")

            # è·å–ä¸‹ä¸€è½®å¯æ‰§è¡ŒåŠ¨ä½œåˆ—è¡¨Actions_{t+1}
            # è¿™äº›åŠ¨ä½œæ˜¯SPæ ¹æ®ä¾èµ–å…³ç³»åˆ¤æ–­å‡ºçš„ã€å¯ä»¥ç«‹å³æ‰§è¡Œçš„å­ä»»åŠ¡
            next_actions = decision.get("next_actions") or decision.get("next_questions", [])
            if not next_actions:
                raise ValueError("Planner suggested to continue search, but provided no actions.")

            # ========== å­æ­¥éª¤2.2ï¼šFEå¤„ç†Actionsâ‚œï¼Œæå–ç»“æ„åŒ–äº‹å®fâ‚œ ==========
            # ä¸ºActionsâ‚œä¸­çš„æ¯ä¸ªå­ä»»åŠ¡páµ¢ï¼Œé€šè¿‡"æ£€ç´¢â†’åˆ†æâ†’æå–"ä¸‰æ­¥ï¼Œç”Ÿæˆé«˜ä¿çœŸçš„ç»“æ„åŒ–äº‹å®
            # å¯¹åº”è®ºæ–‡å…¬å¼ï¼šf_t = M_Î¸(ExtractF | q_t, D_t, F_{t-1}) ï¼ˆå…¬å¼7ï¼‰
            # 
            # å¹¶è¡Œæˆ–ä¸²è¡Œæ‰§è¡Œ next_actionsï¼ˆserial_next_actions=True ç”¨äº Parallel vs Serial å¯¹æ¯”ï¼‰
            if verbose: print(f"\nğŸ” Executing {len(next_actions)} search action(s) {'serially' if serial_next_actions else 'in parallel'}...")
            iteration_new_facts = []  # æœ¬è½®è¿­ä»£æå–çš„æ–°äº‹å®åˆ—è¡¨{fâ‚, fâ‚‚, ..., fâ‚–}
            extraction_had_errors = False  # æ ‡è®°æ˜¯å¦æœ‰æå–é”™è¯¯

            actions_to_run = [a for a in next_actions if any(req['requirement_id'] == a.get("requirement_id") for req in pending_requirements)]

            if serial_next_actions:
                for action in actions_to_run:
                    req = [req for req in pending_requirements if req['requirement_id'] == action.get("requirement_id")][0]
                    newly_extracted_data = rag_core.retrieve_and_extract_facts(
                        search_query=action.get("question"),
                        requirement=req,
                        collected_facts=collected_facts,
                    )
                    if not isinstance(newly_extracted_data, dict) or "reasoned_facts" not in newly_extracted_data:
                        raise ValueError(f"Invalid data structure received for '{action.get('question')}'.")
                    iteration_new_facts.extend(newly_extracted_data.get("reasoned_facts", []))
                    if verbose:
                        print(f"  - ğŸ“ Result for '{action.get('question')}': {len(newly_extracted_data.get('reasoned_facts', []))} fact(s)")
            else:
                # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œæ‰§è¡Œå¤šä¸ªå­ä»»åŠ¡çš„äº‹å®æå–
                with ThreadPoolExecutor() as executor:
                    future_to_action = {
                        executor.submit(
                            partial(copy_context().run, rag_core.retrieve_and_extract_facts),
                            search_query=action.get("question"),
                            requirement=[req for req in pending_requirements if req['requirement_id'] == action.get("requirement_id")][0],
                            collected_facts=collected_facts
                        ): action
                        for action in actions_to_run
                    }
                    for future in as_completed(future_to_action):
                        action = future_to_action[future]
                        try:
                            newly_extracted_data = future.result()
                            if verbose:
                                print(f"  - ğŸ“ Result for '{action.get('question')}':")
                                try:
                                    print(f"    {json.dumps(newly_extracted_data, indent=4, ensure_ascii=False)}")
                                except (TypeError, json.JSONDecodeError):
                                    print(f"    (Could not format non-JSON or invalid JSON output: {newly_extracted_data})")
                            if not isinstance(newly_extracted_data, dict) or "reasoned_facts" not in newly_extracted_data:
                                raise ValueError(f"Invalid data structure received for '{action.get('question')}'.")
                            iteration_new_facts.extend(newly_extracted_data.get("reasoned_facts", []))
                        except Exception as exc:
                            if verbose: print(f"  - âŒ Error processing result for '{action.get('question')}': {exc}")
                            raise RuntimeError(f"Fact extraction failed for '{action.get('question')}'") from exc

            if verbose:
                print(f"  - âœ… Fact extraction phase completed. Found {len(iteration_new_facts)} new fact(s).")

            # ========== å­æ­¥éª¤2.3ï¼ˆéƒ¨åˆ†ï¼‰ï¼šSPæ›´æ–°äº‹å®åˆ—è¡¨F_t ==========
            # å°†æ–°æå–çš„äº‹å®åˆå¹¶åˆ°å†å²äº‹å®ä¸­ï¼Œå¯¹åº”è®ºæ–‡å…¬å¼ï¼šF_t = F_{t-1} âˆª {fâ‚, fâ‚‚, ..., fâ‚–}
            # åŒæ—¶æ ¹æ®æ»¡è¶³åº¦æ ‡ç­¾lâ‚œï¼Œæ›´æ–°å¾…å®Œæˆå­ä»»åŠ¡åˆ—è¡¨å’Œæå–çŠ¶æ€æ ‡è®°
            if iteration_new_facts:
                # å¤„ç†æå–çš„äº‹å®ï¼Œç¡®ä¿æ ¼å¼ç»Ÿä¸€
                processed_facts = []
                for fact in iteration_new_facts:
                    req_id = fact.get("fulfills_requirement_id")
                    if not req_id:
                        continue

                    question = req_id_to_question.get(req_id, "Unknown Question")
                    
                    # æ„å»ºå¤„ç†åçš„ç»“æ„åŒ–äº‹å®ï¼ˆå¯¹åº”å…¬å¼8ï¼šf_t = (s_t, e_t, r_t, l_t)ï¼‰
                    processed_fact = {
                        "fulfills_requirement_id": req_id,  # æ»¡è¶³çš„å­ä»»åŠ¡ID
                        "requirement": question,  # å­ä»»åŠ¡é—®é¢˜
                        "reasoning": fact.get("reasoning"),  # æ¨ç†è¿‡ç¨‹r_t
                        "statement": fact.get("statement"),  # æ ¸å¿ƒé™ˆè¿°s_t
                        "fulfillment_level": fact.get("fulfillment_level")  # æ»¡è¶³åº¦æ ‡ç­¾l_t
                    }
                    processed_fact = {k: v for k, v in processed_fact.items() if v is not None}

                    processed_facts.append(processed_fact)

                # æ›´æ–°äº‹å®åˆ—è¡¨ï¼šF_t = F_{t-1} âˆª {fâ‚, fâ‚‚, ..., fâ‚–}
                collected_facts["reasoned_facts"].extend(processed_facts)
                
                # æ ¹æ®æ»¡è¶³åº¦æ ‡ç­¾lâ‚œï¼Œç§»é™¤å·²å®Œæˆï¼ˆDIRECT_ANSWERï¼‰çš„å­ä»»åŠ¡
                fulfilled_req_ids = {fact['fulfills_requirement_id'] for fact in iteration_new_facts if fact.get("fulfillment_level") == "DIRECT_ANSWER"}
                pending_requirements = [req for req in pending_requirements if req['requirement_id'] not in fulfilled_req_ids]
                
                # æ›´æ–°æå–çŠ¶æ€æ ‡è®°ï¼šå¦‚æœæ‰€æœ‰äº‹å®éƒ½æ˜¯DIRECT_ANSWERä¸”æ— é”™è¯¯ï¼Œæ ‡è®°ä¸ºTrueï¼ˆä¸‹æ¬¡ä½¿ç”¨Plan Updaterï¼‰
                last_extraction_was_direct_only = all(fact.get("fulfillment_level") == "DIRECT_ANSWER" for fact in iteration_new_facts) and not extraction_had_errors
            else:
                # å¦‚æœæ²¡æœ‰æå–åˆ°æ–°äº‹å®ï¼Œæ ‡è®°ä¸ºFalseï¼ˆä¸‹æ¬¡ä½¿ç”¨Re-Plannerï¼‰
                last_extraction_was_direct_only = False

            # ========== è¿­ä»£æˆåŠŸå®Œæˆ ==========
            # æäº¤æ—¥å¿—å¹¶å¢åŠ è¿­ä»£è®¡æ•°
            if current_tracer: current_tracer.commit_pending()
            iteration_count += 1

        except (json.JSONDecodeError, ValueError, RuntimeError) as e:
            # ========== é”™è¯¯å¤„ç†ï¼šçŠ¶æ€å›æ»š ==========
            # å¦‚æœè¿­ä»£è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œå›æ»šåˆ°è¿­ä»£å¼€å§‹å‰çš„çŠ¶æ€ï¼Œç„¶åç»§ç»­ä¸‹ä¸€è½®å°è¯•
            if verbose: 
                print(f"\nâŒ Iteration {iteration_count + 1} failed: {e}")
                print("ğŸ”„ Rolling back state to the beginning of the iteration and retrying.")
            
            # çŠ¶æ€å›æ»šï¼šæ¢å¤åˆ°è¿­ä»£å¼€å§‹å‰çš„çŠ¶æ€
            collected_facts["reasoned_facts"] = facts_before_iteration  # å›æ»šäº‹å®åˆ—è¡¨
            pending_requirements = pending_reqs_before_iteration  # å›æ»šå¾…å®Œæˆè®¡åˆ’
            req_id_to_question = req_map_before_iteration  # å›æ»šIDæ˜ å°„
            last_extraction_was_direct_only = last_direct_before_iteration  # å›æ»šæå–çŠ¶æ€æ ‡è®°
            
            # ä¸¢å¼ƒå¤±è´¥çš„æ—¥å¿—
            if current_tracer: current_tracer.discard_pending()
            
            # ç»§ç»­ä¸‹ä¸€è½®å°è¯•ï¼ˆä¸å¢åŠ iteration_countï¼Œå› ä¸ºè¿™æ¬¡è¿­ä»£å¤±è´¥äº†ï¼‰
            continue
    else:
        # ç»ˆæ­¢æ¡ä»¶3ï¼šè¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆéç†æƒ³ç»ˆæ­¢ï¼‰
        if verbose: print("\nâš ï¸ Warning: Reached maximum iterations. Moving to synthesis with potentially incomplete facts.")

    # ========== é˜¶æ®µ3ï¼šç­”æ¡ˆåˆæˆï¼ˆSynthesizeræ¨¡å—ï¼‰==========
    # åŠŸèƒ½ï¼šè°ƒç”¨LLMï¼ŒåŸºäºæœ€ç»ˆäº‹å®åˆ—è¡¨F_finalä¸­çš„æ‰€æœ‰äº‹å®ï¼Œåˆæˆç¬¦åˆåŸå§‹æŸ¥è¯¢éœ€æ±‚çš„æœ€ç»ˆç­”æ¡ˆ
    # å¯¹åº”è®ºæ–‡å…¬å¼ï¼šA = M_Î¸(Synthesize | Q, F_final) ï¼ˆå…¬å¼4ï¼‰
    if verbose:
        print("\n--- Final Stage: Synthesizing Answer from Collected Facts ---")
        print("Collected Facts Summary:")
        print(json.dumps(collected_facts, indent=2, ensure_ascii=False))
    
    # ä¸¢å¼ƒå¾…å¤„ç†çš„æ—¥å¿—ï¼ˆå¦‚æœæœ‰ï¼‰
    if current_tracer: current_tracer.discard_pending()
    # è°ƒç”¨Synthesizeræ¨¡å—ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
    final_answer = rag_core.synthesize_final_answer(query=query, collected_facts=collected_facts)
    # æäº¤æœ€ç»ˆç­”æ¡ˆç”Ÿæˆçš„æ—¥å¿—
    if current_tracer: current_tracer.commit_pending()
    return final_answer
